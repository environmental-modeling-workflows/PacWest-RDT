{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93f6d128-edd0-4f2c-aaed-69f17d28023d",
   "metadata": {},
   "source": [
    "# Write ATS input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9164ca1-f77f-4673-b44f-d8e1067674b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these can be turned on for development work\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "935c860f-9ea8-456c-acc1-3a91491d49c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up logging first or else it gets preempted by another package\n",
    "import watershed_workflow.ui\n",
    "watershed_workflow.ui.setup_logging(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c4fa8e0-fcc3-4727-bca2-69b10052d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import cftime, datetime\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "import watershed_workflow \n",
    "import watershed_workflow.config\n",
    "import watershed_workflow.sources\n",
    "import watershed_workflow.utils\n",
    "import watershed_workflow.plot\n",
    "import watershed_workflow.mesh\n",
    "import watershed_workflow.regions\n",
    "import watershed_workflow.meteorology\n",
    "import watershed_workflow.land_cover_properties\n",
    "import watershed_workflow.resampling\n",
    "import watershed_workflow.condition\n",
    "import watershed_workflow.io\n",
    "import watershed_workflow.sources.standard_names as names\n",
    "\n",
    "import ats_input_spec\n",
    "import ats_input_spec.public\n",
    "import ats_input_spec.io\n",
    "\n",
    "import amanzi_xml.utils.io as aio\n",
    "import amanzi_xml.utils.search as asearch\n",
    "import amanzi_xml.utils.errors as aerrors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0d63c17-d40a-43d9-88ab-962ff7bf9702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force Watershed Workflow to pull data from this directory rather than a shared data directory.\n",
    "# This picks up the Coweeta-specific datasets set up here to avoid large file downloads for \n",
    "# demonstration purposes.\n",
    "#\n",
    "def splitPathFull(path):\n",
    "    \"\"\"\n",
    "    Splits an absolute path into a list of components such that\n",
    "    os.path.join(*splitPathFull(path)) == path\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    while True:\n",
    "        head, tail = os.path.split(path)\n",
    "        if head == path:  # root on Unix or drive letter with backslash on Windows (e.g., C:\\)\n",
    "            parts.insert(0, head)\n",
    "            break\n",
    "        elif tail == path:  # just a single file or directory\n",
    "            parts.insert(0, tail)\n",
    "            break\n",
    "        else:\n",
    "            parts.insert(0, tail)\n",
    "            path = head\n",
    "    return parts\n",
    "\n",
    "cwd = splitPathFull(os.getcwd())\n",
    "assert cwd[-1] == 'workflow'\n",
    "cwd = cwd[:-1]\n",
    "\n",
    "# Note, this directory is where downloaded data will be put as well\n",
    "data_dir = os.path.join(*(cwd + ['input_data',]))\n",
    "def toInput(filename):\n",
    "    return os.path.join(data_dir, filename)\n",
    "\n",
    "output_filenames = dict()\n",
    "output_dir = os.path.join(*(cwd + ['output_data',]))\n",
    "def fromOutput(filename):\n",
    "    return os.path.join(output_dir, filename)    \n",
    "\n",
    "def toOutput(role, filename):\n",
    "    output_filenames[role] = filename\n",
    "    return fromOutput(filename)\n",
    "\n",
    "# check output and input dirs exist\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6158b47e-bea0-4b56-85dd-701471678155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data directory to the local space to get the locally downloaded files\n",
    "# REMOVE THIS CELL for general use outside fo Coweeta\n",
    "watershed_workflow.config.setDataDirectory(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0450d12-1c42-43ad-bfaa-b9847b92e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters cell -- this provides all parameters that can be changed via pipelining to generate a new watershed. \n",
    "name = 'RussianRiver'\n",
    "hucs = ['18010110'] # a list of HUCs to run\n",
    "\n",
    "# Geometric parameters\n",
    "# -- parameters to clean and reduce the river network prior to meshing\n",
    "prune_by_area = 10               # km^2\n",
    "simplify = 125                   # length scale to target average edge \n",
    "\n",
    "# -- mesh triangle refinement control\n",
    "refine_d0 = 200\n",
    "refine_d1 = 600\n",
    "\n",
    "refine_L0 = 125\n",
    "refine_L1 = 300\n",
    "\n",
    "refine_A0 = refine_L0**2 / 2\n",
    "refine_A1 = refine_L1**2 / 2\n",
    "\n",
    "# Refine triangles if they get too acute\n",
    "min_angle = 20 # degrees\n",
    "\n",
    "# width of reach by stream order (order:width)\n",
    "river_widths = dict({1:10, 2:10, 3:20, 4:30, 5:30}) \n",
    "\n",
    "\n",
    "# Note that, by default, we tend to work in the DayMet CRS because this allows us to avoid\n",
    "# reprojecting meteorological forcing datasets.\n",
    "crs = watershed_workflow.crs.default_crs\n",
    "\n",
    "\n",
    "# start and stop time for simulation\n",
    "# note that this is the overlap of AORC and MODIS\n",
    "start = cftime.DatetimeGregorian(2007, 8, 1)\n",
    "end = cftime.DatetimeGregorian(2020, 7, 31)\n",
    "\n",
    "start_noleap = cftime.DatetimeNoLeap(2007, 8, 1)\n",
    "end_noleap = cftime.DatetimeNoLeap(2020, 7, 31)\n",
    "cyclic_nyears = 10\n",
    "\n",
    "\n",
    "# Global Soil Properties\n",
    "min_porosity = 0.05 # minimum porosity considered \"too small\"\n",
    "max_permeability = 1.e-10 # max value considered \"too permeable\"\n",
    "max_vg_alpha = 1.e-3 # max value of van Genuchten's alpha -- our correlation is not valid for some soils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4daf89-8162-4fb7-945f-4f4f3685c49a",
   "metadata": {},
   "source": [
    "## Helper functions for creating input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b8f7c5e-1aaa-475c-8d7c-5235ff92cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that each of these are defined as functions so we can reuse them for all three input files.\n",
    "\n",
    "# add the subsurface and surface domains\n",
    "#\n",
    "# Note this also adds a \"computational domain\" region to the region list, and a vis spec \n",
    "# for \"domain\"\n",
    "def add_domains(main_list, mesh, surface_region='surface', snow=True, canopy=True):\n",
    "    ats_input_spec.public.add_domain(main_list, \n",
    "                                 domain_name='domain', \n",
    "                                 dimension=3, \n",
    "                                 mesh_type='read mesh file',\n",
    "                                 mesh_args={'file':mesh})\n",
    "    if surface_region:\n",
    "        main_list['mesh']['domain']['build columns from set'] = surface_region    \n",
    "    \n",
    "        # Note this also adds a \"surface domain\" region to the region list and a vis spec for \n",
    "        # \"surface\"\n",
    "        ats_input_spec.public.add_domain(main_list,\n",
    "                                domain_name='surface',\n",
    "                                dimension=2,\n",
    "                                mesh_type='surface',\n",
    "                                mesh_args={'surface sideset name':'surface'})\n",
    "    if snow:\n",
    "        # Add the snow and canopy domains, which are aliases to the surface\n",
    "        ats_input_spec.public.add_domain(main_list,\n",
    "                                domain_name='snow',\n",
    "                                dimension=2,\n",
    "                                mesh_type='aliased',\n",
    "                                mesh_args={'target':'surface'})\n",
    "    if canopy:\n",
    "        ats_input_spec.public.add_domain(main_list,\n",
    "                                domain_name='canopy',\n",
    "                                dimension=2,\n",
    "                                mesh_type='aliased',\n",
    "                                mesh_args={'target':'surface'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4f3866-5cf1-4974-ba13-c3b8a93a5e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_land_cover(main_list, nlcd_indices, nlcd_names):\n",
    "    # next write a land-cover section for each NLCD type\n",
    "    for nlcd_index, nlcd_name in zip(nlcd_indices, nlcd_labels):\n",
    "        ats_input_spec.public.set_land_cover_default_constants(main_list, nlcd_name)\n",
    "\n",
    "    land_cover_list = main_list['state']['model parameters']['land cover types']\n",
    "    # update some defaults for\n",
    "    # ['Other', 'Deciduous Forest']\n",
    "    # note, these are from the CLM Technical Note v4.5\n",
    "    #\n",
    "    # Rooting depth curves from CLM TN 4.5 table 8.3\n",
    "    #\n",
    "    # Note, the mafic potential values are likely pretty bad for the types of van Genuchten \n",
    "    # curves we are using (ETC -- add paper citation about this topic).  Likely they need\n",
    "    # to be modified.  Note that these values are in [mm] from CLM TN 4.5 table 8.1, so the \n",
    "    # factor of 10 converts to [Pa]\n",
    "    #\n",
    "    # Note, albedo of canopy taken from CLM TN 4.5 table 3.1\n",
    "    land_cover_list['Deciduous Forest']['rooting profile alpha [-]'] = 6.0\n",
    "    land_cover_list['Deciduous Forest']['rooting profile beta [-]'] = 2.0\n",
    "    land_cover_list['Deciduous Forest']['rooting depth max [m]'] = 10.0\n",
    "    land_cover_list['Deciduous Forest']['capillary pressure at fully closed stomata [Pa]'] = 224000\n",
    "    land_cover_list['Deciduous Forest']['capillary pressure at fully open stomata [Pa]'] = 35000 * .10\n",
    "    land_cover_list['Deciduous Forest']['albedo of canopy [-]'] = 0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9af68a-cb1f-4dbf-a160-6637f9bfaf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add soil sets: note we need a way to name the set, so we use, e.g. SSURGO-MUKEY.\n",
    "def soil_set_name(ats_id):\n",
    "    return subsurface_props_used.loc[ats_id, 'name']\n",
    "\n",
    "def add_soil_properties(main_list):\n",
    "    # add soil material ID regions, porosity, permeability, and WRMs\n",
    "    for ats_id in subsurface_props_used.index:\n",
    "        props = subsurface_props_used.loc[ats_id]\n",
    "        set_name = soil_set_name(ats_id)\n",
    "        \n",
    "        if props['van Genuchten n [-]'] < 1.5:\n",
    "            smoothing_interval = 0.01\n",
    "        else:\n",
    "            smoothing_interval = 0.0\n",
    "        \n",
    "        ats_input_spec.public.add_soil_type(main_list, set_name, ats_id, output_filenames['mesh'],\n",
    "                                            float(props['porosity [-]']),\n",
    "                                            float(props['permeability [m^2]']), 1.e-7,\n",
    "                                            float(props['van Genuchten alpha [Pa^-1]']),\n",
    "                                            float(props['van Genuchten n [-]']),\n",
    "                                            float(props['residual saturation [-]']),\n",
    "                                            float(smoothing_interval))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e77d0-49e7-4266-b7db-f64d9ea36fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an ATS \"main\" input spec list -- note, this is a dummy and is not used to write any files yet\n",
    "def get_main(steadystate=False):\n",
    "    main_list = ats_input_spec.public.get_main()\n",
    "\n",
    "    # add the mesh and all domains\n",
    "    mesh = os.path.join('..', output_filenames['mesh'])\n",
    "    add_domains(main_list, mesh)\n",
    "\n",
    "    # add labeled sets\n",
    "    for ls in m3.labeled_sets:\n",
    "        ats_input_spec.public.add_region_labeled_set(main_list, ls.name, ls.setid, mesh, ls.entity)\n",
    "    for ss in m3.side_sets:\n",
    "        ats_input_spec.public.add_region_labeled_set(main_list, ss.name, ss.setid, mesh, 'FACE')\n",
    "    \n",
    "    # add land cover\n",
    "    add_land_cover(main_list)\n",
    "\n",
    "    # add soil properties\n",
    "    add_soil_properties(main_list)\n",
    "        \n",
    "    # add observations for each subcatchment\n",
    "    if steadystate:\n",
    "        time_args = {'cycles start period stop':[0,10,-1],}\n",
    "    else:\n",
    "        time_args = None\n",
    "    ats_input_spec.public.add_observations_water_balance(main_list, \"computational domain\", \n",
    "                                                        \"surface domain\", \"external sides\",\n",
    "                                                        time_args=time_args)\n",
    "\n",
    "    return main_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a2e2e0-4d38-4eb2-9f4a-12a533381b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_basic_properties(xml, main_xml):\n",
    "    \"\"\"This function updates an xml object with the above properties for mesh, regions, soil props, and lc props\"\"\"\n",
    "    # find and replace the mesh list\n",
    "    xml.replace('mesh', asearch.child_by_name(main_xml, 'mesh'))\n",
    "\n",
    "    # find and replace the regions list\n",
    "    xml.replace('regions', asearch.child_by_name(main_xml, 'regions'))\n",
    "\n",
    "    # update the observations list\n",
    "    obs = next(i for (i,el) in enumerate(xml) if el.get('name') == 'observations')\n",
    "    xml[obs] = asearch.child_by_name(main_xml, 'observations')\n",
    "\n",
    "    # update all model parameters lists\n",
    "    xml_parlist = asearch.find_path(xml, ['state', 'model parameters'], no_skip=True)\n",
    "    for parlist in asearch.find_path(main_xml, ['state', 'model parameters'], no_skip=True):\n",
    "        try:\n",
    "            xml_parlist.replace(parlist.getName(), parlist)\n",
    "        except aerrors.MissingXMLError:\n",
    "            xml_parlist.append(parlist)\n",
    "\n",
    "    # update all evaluator lists\n",
    "    xml_elist = asearch.find_path(xml, ['state', 'evaluators'], no_skip=True)\n",
    "    for elist in asearch.find_path(main_xml, ['state', 'evaluators'], no_skip=True):\n",
    "        try:\n",
    "            xml_elist.replace(elist.getName(), elist)\n",
    "        except aerrors.MissingXMLError:\n",
    "            xml_elist.append(elist)    \n",
    "    \n",
    "    # find and replace land cover\n",
    "    mp_list = asearch.find_path(xml, ['state', 'model parameters'], no_skip=True)\n",
    "    lc_list = asearch.find_path(main_xml, ['state', 'model parameters', 'land cover types'], no_skip=True)\n",
    "    \n",
    "    try:\n",
    "        mp_list.replace('land cover types', lc_list)\n",
    "    except aerrors.MissingXMLError:\n",
    "        mp_list.append(lc_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5403e940-a1c8-4787-bc28-50015a855b29",
   "metadata": {},
   "source": [
    "## Write the files\n",
    "\n",
    "### Steadystate spinup step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae026b57-97ed-437a-8dd3-3f8f7855bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the main list\n",
    "main = get_main()\n",
    "\n",
    "# set precip to 0.6 * the mean precip value\n",
    "precip = main['state']['evaluators'].append_empty('surface-precipitation')\n",
    "precip.set_type('independent variable constant', ats_input_spec.public.known_specs['evaluator-independent-variable-constant-spec'])\n",
    "precip['value'] = float(precip_mean * .6)\n",
    "    \n",
    "# load the template file\n",
    "prefix = 'steadystate'\n",
    "xml = aio.fromFile(toInput(f'{prefix}-template.xml'))\n",
    "    \n",
    "# update the template xml with the main xml generated here\n",
    "main_xml = ats_input_spec.io.to_xml(main)\n",
    "populate_basic_properties(xml, main_xml, **kwargs)\n",
    "\n",
    "# write to disk\n",
    "output_filenames[f'ats_xml_{prefix}'] = toWorkingDir(f'{name}-{prefix}.xml')\n",
    "filename = output_filenames[f'ats_xml_{prefix}']\n",
    "aio.toFile(xml, filename)\n",
    "\n",
    "# create a run directory\n",
    "output_filenames[f'ats_rundir_{prefix}'] = toWorkingDir(f'{name}-{prefix}')\n",
    "rundir = output_filenames[f'ats_rundir_{prefix}']\n",
    "os.makedirs(rundir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1053f1b-ff33-4568-914a-dda1a2c70909",
   "metadata": {},
   "source": [
    "### Cyclic steadystate spinup step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e9318-ef05-4ebe-9a24-5dd158a22823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c6ae99a-8893-42e5-8530-b4d1c6b6fe4a",
   "metadata": {},
   "source": [
    "### Transient simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a34dc6-498a-45da-9ce6-56d436b6a5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ww-geopandas-20250725]",
   "language": "python",
   "name": "conda-env-ww-geopandas-20250725-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
