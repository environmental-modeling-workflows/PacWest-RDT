{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae9f8df9-b87a-43f1-875b-e49355841d4c",
   "metadata": {},
   "source": [
    "# Land Cover\n",
    "\n",
    "Gets MODIS, NLCD, and performs the crosswalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee47c56d-0fd8-456e-9649-a5cad00f3aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a905290-002d-43d8-8211-1c5f28484ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298b9787-45bc-4381-8c28-6008eacd797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up logging first or else it gets preempted by another package\n",
    "import watershed_workflow.ui\n",
    "watershed_workflow.ui.setup_logging(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04228d5b-7d25-4c0b-881d-e59da3b4dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import logging\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import shapely\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "import cftime\n",
    "import datetime\n",
    "\n",
    "import watershed_workflow \n",
    "import watershed_workflow.config\n",
    "import watershed_workflow.sources\n",
    "import watershed_workflow.mesh\n",
    "import watershed_workflow.regions\n",
    "import watershed_workflow.land_cover_properties\n",
    "import watershed_workflow.io\n",
    "\n",
    "# set the default figure size for notebooks\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423c3eb9-48da-44ad-874f-80d4dde94fe4",
   "metadata": {},
   "source": [
    "## Input: Parameters and other source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446fba62-bf77-4a86-9e6e-9b106b6127d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force Watershed Workflow to pull data from this directory rather than a shared data directory.\n",
    "# This picks up the Coweeta-specific datasets set up here to avoid large file downloads for \n",
    "# demonstration purposes.\n",
    "#\n",
    "def splitPathFull(path):\n",
    "    \"\"\"\n",
    "    Splits an absolute path into a list of components such that\n",
    "    os.path.join(*splitPathFull(path)) == path\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    while True:\n",
    "        head, tail = os.path.split(path)\n",
    "        if head == path:  # root on Unix or drive letter with backslash on Windows (e.g., C:\\)\n",
    "            parts.insert(0, head)\n",
    "            break\n",
    "        elif tail == path:  # just a single file or directory\n",
    "            parts.insert(0, tail)\n",
    "            break\n",
    "        else:\n",
    "            parts.insert(0, tail)\n",
    "            path = head\n",
    "    return parts\n",
    "\n",
    "cwd = splitPathFull(os.getcwd())\n",
    "assert cwd[-1] == 'workflow'\n",
    "cwd = cwd[:-1]\n",
    "\n",
    "# Note, this directory is where downloaded data will be put as well\n",
    "data_dir = os.path.join(*(cwd + ['input_data',]))\n",
    "def toInput(filename):\n",
    "    return os.path.join(data_dir, filename)\n",
    "\n",
    "output_filenames = dict()\n",
    "output_dir = os.path.join(*(cwd + ['output_data',]))\n",
    "def fromOutput(filename):\n",
    "    return os.path.join(output_dir, filename)    \n",
    "\n",
    "def toOutput(role, filename):\n",
    "    output_filenames[role] = filename\n",
    "    return fromOutput(filename)\n",
    "\n",
    "# check output and input dirs exist\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b7dd0-5c03-4c44-89db-70bcfc301d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data directory to the local space to get the locally downloaded files\n",
    "# REMOVE THIS CELL for general use outside fo Coweeta\n",
    "watershed_workflow.config.setDataDirectory(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12facfb0-7550-4876-b095-48ad59189104",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters cell -- this provides all parameters that can be changed via pipelining to generate a new watershed. \n",
    "name = 'RussianRiver'\n",
    "hucs = ['18010110'] # a list of HUCs to run\n",
    "\n",
    "# Geometric parameters\n",
    "# -- parameters to clean and reduce the river network prior to meshing\n",
    "prune_by_area = 10               # km^2\n",
    "simplify = 125                   # length scale to target average edge \n",
    "\n",
    "# -- mesh triangle refinement control\n",
    "refine_d0 = 200\n",
    "refine_d1 = 600\n",
    "\n",
    "refine_L0 = 125\n",
    "refine_L1 = 300\n",
    "\n",
    "refine_A0 = refine_L0**2 / 2\n",
    "refine_A1 = refine_L1**2 / 2\n",
    "\n",
    "# Refine triangles if they get too acute\n",
    "min_angle = 20 # degrees\n",
    "\n",
    "# width of reach by stream order (order:width)\n",
    "river_widths = dict({1:10, 2:10, 3:20, 4:30, 5:30}) \n",
    "\n",
    "\n",
    "# Note that, by default, we tend to work in the DayMet CRS because this allows us to avoid\n",
    "# reprojecting meteorological forcing datasets.\n",
    "crs = watershed_workflow.crs.default_crs\n",
    "\n",
    "\n",
    "# start and stop time for simulation\n",
    "# note that this is the overlap of AORC and MODIS\n",
    "start = cftime.DatetimeGregorian(2007, 8, 1)\n",
    "end = cftime.DatetimeGregorian(2020, 7, 31)\n",
    "\n",
    "start_noleap = cftime.DatetimeNoLeap(2007, 8, 1)\n",
    "end_noleap = cftime.DatetimeNoLeap(2020, 7, 31)\n",
    "cyclic_nyears = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7cd6c2-7473-4183-a848-8204ffe23e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a dictionary of source objects\n",
    "#\n",
    "# Data sources, also called managers, deal with downloading and parsing data files from a variety of online APIs.\n",
    "sources = watershed_workflow.sources.getDefaultSources()\n",
    "\n",
    "# log the sources that will be used here\n",
    "watershed_workflow.sources.logSources(sources)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e093ae-180a-483a-b36b-e818c76352d5",
   "metadata": {},
   "source": [
    "## Reload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d3075e-ce93-4248-b831-14056a57914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fromOutput('02_watersheds.pickle'), 'rb') as fid:\n",
    "    watersheds = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef3c946-0385-48d4-990d-af1a847a1210",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fromOutput('03_m2.pickle'), 'rb') as fid:\n",
    "    m2 = pickle.load(fid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b3bcfe-40c7-4f64-a88c-829d4478361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = gpd.GeoDataFrame(geometry=[watersheds.exterior,], crs=watersheds.crs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9126e68b-a204-44e7-b787-b5790506915d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ls in m2.labeled_sets:\n",
    "    print(f'\"{ls.name}\" : {ls.setid} consists of {len(ls.ent_ids)} {ls.entity}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0aa8fa-aa9c-420d-967e-a1856a2e2381",
   "metadata": {},
   "source": [
    "## Get NLCD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e9e227-6f06-48a5-8073-ca968ee882d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the NLCD raster\n",
    "nlcd = sources['land cover'].getDataset(watersheds.exterior, watersheds.crs)['cover']\n",
    "\n",
    "# what land cover types did we get?\n",
    "logging.info('Found land cover dtypes: {}'.format(nlcd.dtype))\n",
    "logging.info('Found land cover types: {}'.format(set(list(nlcd.values.ravel()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2090ac80-2353-49b9-b144-50c76c555b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a colormap for the data\n",
    "nlcd_indices, nlcd_cmap, nlcd_norm, nlcd_ticks, nlcd_labels = \\\n",
    "      watershed_workflow.colors.createNLCDColormap(np.unique(nlcd))\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "ax = fig.add_axes([0.1, 0.1, 0.55, 0.85])\n",
    "\n",
    "nlcd.plot.imshow(ax=ax, cmap=nlcd_cmap, norm=nlcd_norm, add_colorbar=False)\n",
    "watershed_workflow.colors.createIndexedColorbar(ncolors=len(nlcd_indices), \n",
    "                               cmap=nlcd_cmap, labels=nlcd_labels, norm=nlcd_norm, ax=ax) \n",
    "ax.set_title('Land Cover')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c5be33-29ba-4947-be3e-26b32d8dc36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map nlcd onto the mesh\n",
    "m2_nlcd = watershed_workflow.getDatasetOnMesh(m2, nlcd, method='nearest')\n",
    "m2.cell_data['land_cover'] = m2_nlcd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f09f7d-3cfc-4279-8a7c-af7bb19e7c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double-check that nan not in the values\n",
    "assert 127 not in m2_nlcd\n",
    "\n",
    "# create a new set of labels and indices with only those that actually appear on the mesh\n",
    "nlcd_indices, nlcd_cmap, nlcd_norm, nlcd_ticks, nlcd_labels = \\\n",
    "      watershed_workflow.colors.createNLCDColormap(np.unique(m2_nlcd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b554252-8c89-4023-bbdc-da7b11015cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labeled sets to the mesh for NLCD\n",
    "nlcd_labels_dict = dict(zip(nlcd_indices, nlcd_labels))\n",
    "watershed_workflow.regions.addSurfaceRegions(m2, names=nlcd_labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6be38f-24b3-40aa-870c-8497bcf5dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ls in m2.labeled_sets:\n",
    "    print(f'{ls.setid} : {ls.entity} : {len(ls.ent_ids)} : \"{ls.name}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a076df8-d503-42db-9361-61ddbd87563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the mesh to disk with new NLCD labels\n",
    "with open(toOutput('m2', '04_m2.pickle'), 'wb') as fid:\n",
    "    pickle.dump(m2, fid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b080eaee-bb60-41d2-8d13-a589853e9aa5",
   "metadata": {},
   "source": [
    "## MODIS LAI\n",
    "\n",
    "Leaf area index is needed on each land cover type -- this is used in the Evapotranspiration calculation.\n",
    "\n",
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a853f6-29b2-4ede-86ca-6b6394fc99f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download LAI and corresponding LULC datasets -- these are actually already downloaded, \n",
    "# as the MODIS AppEEARS API is quite slow\n",
    "#\n",
    "# get the full LAI record\n",
    "#req = sources['LAI'].requestDataset(watersheds.exterior, crs, task_id='29411e08-5863-48c0-8b86-84e44334b846')\n",
    "req = sources['LAI'].requestDataset(watersheds.exterior, crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92d426d-42cd-4924-82e9-cc44f9d392a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources['LAI'].isReady(req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ec9b9-c67c-4ef2-8dec-73390e4fd79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_data = sources['LAI'].fetchRequest(req)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87543eb5-888b-43bc-9b22-fd52e8f58aea",
   "metadata": {},
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964f0cb2-db23-4bb5-aadc-df7fcdaa194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIS data comes with time-dependent LAI AND time-dependent LULC -- just take the mode to find the most common LULC\n",
    "modis_data['LULC'] = watershed_workflow.data.computeMode(modis_data['LULC'], 'time_LULC')\n",
    "\n",
    "# now it is safe to have only one time\n",
    "modis_data = modis_data.rename({'time_LAI':'time'})\n",
    "\n",
    "# remove leap day (366th day of any leap year) to use a Noleap Calendar\n",
    "modis_data = watershed_workflow.data.filterLeapDay(modis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642115e4-191b-4680-b02b-1cdc36e1c30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the MODIS data\n",
    "modis_data['LULC'].plot.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693805ad-b8e2-422d-a47e-71f04bec8601",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,5))\n",
    "\n",
    "time_xax = modis_data['time'] - start_noleap\n",
    "ax.plot(time_xax, modis_data['LAI'][:, 18, 21])\n",
    "\n",
    "#ax.set_xlim(0, 365 * 86400 * 1e9) # to zoom in to one year, convert time to nano-seconds\n",
    "ax.set_ylim(0,4)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f7584c-7b84-426b-8521-38c301464901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the transient time series by class\n",
    "modis_lai_ts = watershed_workflow.land_cover_properties.computeTimeSeries(modis_data['LAI'], modis_data['LULC'], \n",
    "                                                                          polygon=watersheds.exterior, polygon_crs=watersheds.crs)\n",
    "\n",
    "# also just compute the mean value time series\n",
    "modis_lai_domain_avg_ts = modis_data['LAI'].mean(dim=('lat', 'lon'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72498625-f859-4fe8-8a39-865202906eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "\n",
    "watershed_workflow.land_cover_properties.plotLAI(modis_lai_ts, indices='MODIS', ax=ax)\n",
    "ax.set_ylim(0,5)\n",
    "ax.set_xlim(14534, 15000)\n",
    "modis_lai_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccdb5fd-f25f-48c8-b547-92051583c1cf",
   "metadata": {},
   "source": [
    "### Evaluate simplified models of LAI relative to full spatial-temporal data\n",
    "\n",
    "So the first question -- is the LAI well represented by just a time series and a LULC class?\n",
    "\n",
    "Let's compute the class-averaged LAI time series, then compare each pixel to its class-average time series, and compute spatial and temporal patterns of RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57450a0-81ea-4446-9769-ea258ec3cb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the error made by assuming LAI is represented by the class average\n",
    "error = np.array([[modis_data['LAI'][:,i,j] - modis_lai_ts[watershed_workflow.sources.manager_modis_appeears.colors[int(modis_data['LULC'][i,j])][0] + ' LAI [-]'] for j in range(modis_data['LULC'].shape[1])] for i in range(modis_data['LULC'].shape[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c472d-0015-49ab-b729-181e3eb79681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spatial MAE map\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "im = ax.imshow(np.linalg.norm(error, ord=1, axis=2) / len(modis_lai_ts), cmap=\"viridis\", vmax=5)\n",
    "plt.colorbar(im)\n",
    "ax.set_title(\"Mean Absolute Error\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9671e7b-de65-4f43-ba42-147ff7110218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the error made by assuming LAI is constant across the domain\n",
    "error_total = modis_data['LAI'] - modis_lai_domain_avg_ts\n",
    "\n",
    "# this is the total variance of the LAI\n",
    "V_total = (error_total**2).mean(dim=('lat','lon'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec91233-17f4-4936-b710-0103f36cfda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now compute the within-class variance\n",
    "V_within  = xr.zeros_like(V_total)  # will accumulate within-class variance\n",
    "\n",
    "# Fraction of pixels in each class\n",
    "pixel_frac = modis_data['LULC'].groupby(modis_data['LULC']).count() / modis_data['LULC'].size # dict: class -> fraction\n",
    "\n",
    "# Compute within-class variance at each time\n",
    "for c in np.unique(modis_data['LULC']):\n",
    "    mask = (modis_data['LULC'] == c)\n",
    "    # mask LAI to only class c\n",
    "    lai_c = modis_data['LAI'].where(mask)\n",
    "    # compute variance over spatial dims (ignoring NaNs for masked pixels)\n",
    "    var_c = lai_c.var(dim=('lat', 'lon'), skipna=True)\n",
    "    # weight by pixel fraction\n",
    "    frac_c = mask.sum() / mask.size\n",
    "    V_within += frac_c * var_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaae10c-d964-421b-a50b-ef129455d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot temporal error ratio -- what is R2 of the ratio of within-class variance to total variance?\n",
    "r2 = 1 - V_within / V_total\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(r2)\n",
    "ax.set_xlabel('time')\n",
    "ax.set_ylabel('error ratio: class-avg to domain-avg')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f69734-8832-4c29-be34-ea6f639998e2",
   "metadata": {},
   "source": [
    "It looks like class-based is a reasonable choice for this domain -- the within-class variance is MUCH smaller than the total variance\n",
    "\n",
    "This convinces us that class-based LAI is good enough.\n",
    "\n",
    "### Continue to process and write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064ccab6-1d15-4b58-a387-37191df03dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth the data in time\n",
    "modis_lai_smoothed = watershed_workflow.data.smoothTimeSeries(modis_lai_ts, 'time', window_length=31)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "watershed_workflow.land_cover_properties.plotLAI(modis_lai_smoothed, indices='MODIS', ax=ax)\n",
    "ax.set_ylim(0,5)\n",
    "ax.set_xlim(14534, 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1429ffa5-0579-482f-aece-6778de8583fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute a typical year\n",
    "modis_lai_typical = watershed_workflow.data.computeAverageYear(modis_lai_smoothed,\n",
    "                                                              start_date = start_noleap - datetime.timedelta(days=365*cyclic_nyears),\n",
    "                                                              output_nyears=cyclic_nyears, \n",
    "                                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7247ab-6aea-47bc-b026-2efdb1e3493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "watershed_workflow.land_cover_properties.plotLAI(modis_lai_typical, indices='MODIS', ax=ax)\n",
    "modis_lai_typical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adadffb-7202-4d9e-9faf-9ce918a32f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the raw data to the window we want\n",
    "modis_lai_ts_limited = modis_lai_ts[(modis_lai_smoothed[\"time\"] >= start_noleap) & (modis_lai_smoothed[\"time\"] <= end_noleap)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c533382-d27b-4f56-89cc-e53f124efd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_lai_typical['time'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b63ebf-7cee-4168-9ce2-8c704a889fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the two time series files -- modis data\n",
    "fname_modis_lai_typical = toOutput('modis_lai_typical', f'RussianRiver_LAI_MODIS_CyclicSteadystate_{modis_lai_typical['time'].iloc[0].year}_{modis_lai_typical['time'].iloc[-1].year}.h5')\n",
    "watershed_workflow.io.writeTimeseriesToHDF5(fname_modis_lai_typical, modis_lai_typical)\n",
    "\n",
    "fname_modis_lai_ts = toOutput('modis_lai_ts', f'RussianRiver_LAI_MODIS_Transient_{modis_lai_ts_limited['time'].iloc[0].year}_{modis_lai_ts_limited['time'].iloc[-1].year}.h5')\n",
    "watershed_workflow.io.writeTimeseriesToHDF5(fname_modis_lai_ts, modis_lai_ts_limited)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a3c61-48d9-4beb-b465-7d6a9e6d1bb2",
   "metadata": {},
   "source": [
    "## Compute the crosswalk of NLCD and MODIS\n",
    "\n",
    "This tells us how to map MODIS LAI onto NLCD classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86045793-5d10-42a1-a22f-29a2dfd97fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosswalk = watershed_workflow.land_cover_properties.computeCrosswalk(modis_data['LULC'], nlcd, method='fractional area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702bb2ea-8d56-40fa-b1b1-e28273b8468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the NLCD-based time series\n",
    "nlcd_lai_typical = watershed_workflow.land_cover_properties.applyCrosswalk(crosswalk, modis_lai_typical)\n",
    "watershed_workflow.land_cover_properties.removeNullLAI(nlcd_lai_typical)\n",
    "\n",
    "\n",
    "nlcd_lai_ts = watershed_workflow.land_cover_properties.applyCrosswalk(crosswalk, modis_lai_ts_limited)\n",
    "watershed_workflow.land_cover_properties.removeNullLAI(nlcd_lai_ts)\n",
    "\n",
    "nlcd_lai_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0504f1-106c-41cc-9a12-6bace4a30f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the two time series files -- NLCD data\n",
    "fname_nlcd_lai_typical = toOutput('nlcd_lai_typical', f'RussianRiver_LAI_NLCD_CyclicSteadystate_{nlcd_lai_typical['time'].iloc[0].year}_{nlcd_lai_typical['time'].iloc[-1].year}.h5')\n",
    "watershed_workflow.io.writeTimeseriesToHDF5(fname_nlcd_lai_typical, nlcd_lai_typical)\n",
    "\n",
    "\n",
    "fname_nlcd_lai_ts = toOutput('nlcd_lai_ts', f'RussianRiver_LAI_NLCD_Transient_{nlcd_lai_ts['time'].iloc[0].year}_{nlcd_lai_ts['time'].iloc[-1].year}.h5')\n",
    "watershed_workflow.io.writeTimeseriesToHDF5(fname_nlcd_lai_ts, nlcd_lai_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e8416-7661-4d2a-bd4b-ac1a3d523dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lastly, reread, update, and output filenames\n",
    "with open(toOutput('04_output_filenames', '04_output_filenames.txt'), 'wb') as fid:\n",
    "    pickle.dump(output_filenames, fid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71f844-267f-4fad-a921-298dd7b382dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ww-geopandas-20250725]",
   "language": "python",
   "name": "conda-env-ww-geopandas-20250725-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
