{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cac45df6-4fdb-4984-a5de-0691b4aaf202",
   "metadata": {},
   "source": [
    "# Meteorological data\n",
    "\n",
    "Gets AORC data for the domain and time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e9ac1d-a4fa-427e-9710-5c8ad47f921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3ad306-9f1b-4d3d-93c7-b0ad5e195801",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18d4322-22b5-4e67-ad2d-3dcda137abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up logging first or else it gets preempted by another package\n",
    "import watershed_workflow.ui\n",
    "watershed_workflow.ui.setup_logging(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2ff5c8-9630-4d7f-8bac-05522e188c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import logging\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import shapely\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "import cftime\n",
    "\n",
    "import watershed_workflow \n",
    "import watershed_workflow.config\n",
    "import watershed_workflow.sources\n",
    "import watershed_workflow.mesh\n",
    "import watershed_workflow.regions\n",
    "import watershed_workflow.meteorology\n",
    "import watershed_workflow.io\n",
    "\n",
    "# set the default figure size for notebooks\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6d9098-457e-4bde-910c-16692f8573fd",
   "metadata": {},
   "source": [
    "## Input: Parameters and other source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b41a5f5-eb89-49eb-8440-98567867c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force Watershed Workflow to pull data from this directory rather than a shared data directory.\n",
    "# This picks up the Coweeta-specific datasets set up here to avoid large file downloads for \n",
    "# demonstration purposes.\n",
    "#\n",
    "def splitPathFull(path):\n",
    "    \"\"\"\n",
    "    Splits an absolute path into a list of components such that\n",
    "    os.path.join(*splitPathFull(path)) == path\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    while True:\n",
    "        head, tail = os.path.split(path)\n",
    "        if head == path:  # root on Unix or drive letter with backslash on Windows (e.g., C:\\)\n",
    "            parts.insert(0, head)\n",
    "            break\n",
    "        elif tail == path:  # just a single file or directory\n",
    "            parts.insert(0, tail)\n",
    "            break\n",
    "        else:\n",
    "            parts.insert(0, tail)\n",
    "            path = head\n",
    "    return parts\n",
    "\n",
    "cwd = splitPathFull(os.getcwd())\n",
    "assert cwd[-1] == 'workflow'\n",
    "cwd = cwd[:-1]\n",
    "\n",
    "# Note, this directory is where downloaded data will be put as well\n",
    "data_dir = os.path.join(*(cwd + ['input_data',]))\n",
    "def toInput(filename):\n",
    "    return os.path.join(data_dir, filename)\n",
    "\n",
    "output_dir = os.path.join(*(cwd + ['output_data',]))\n",
    "output_filenames = dict()\n",
    "def fromOutput(filename):\n",
    "    return os.path.join(output_dir, filename)    \n",
    "\n",
    "def toOutput(role, filename):\n",
    "    output_filenames[role] = filename\n",
    "    return fromOutput(filename)\n",
    "\n",
    "# check output and input dirs exist\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ccd88-de2f-4dac-9a90-b35d39a6346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data directory to the local space to get the locally downloaded files\n",
    "# REMOVE THIS CELL for general use outside fo Coweeta\n",
    "watershed_workflow.config.setDataDirectory(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd313feb-1bd6-47b9-be24-7502baae9051",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters cell -- this provides all parameters that can be changed via pipelining to generate a new watershed. \n",
    "name = 'RussianRiver'\n",
    "hucs = ['18010110'] # a list of HUCs to run\n",
    "\n",
    "# Geometric parameters\n",
    "# -- parameters to clean and reduce the river network prior to meshing\n",
    "prune_by_area = 10               # km^2\n",
    "simplify = 125                   # length scale to target average edge \n",
    "\n",
    "# -- mesh triangle refinement control\n",
    "refine_d0 = 200\n",
    "refine_d1 = 600\n",
    "\n",
    "refine_L0 = 125\n",
    "refine_L1 = 300\n",
    "\n",
    "refine_A0 = refine_L0**2 / 2\n",
    "refine_A1 = refine_L1**2 / 2\n",
    "\n",
    "# Refine triangles if they get too acute\n",
    "min_angle = 20 # degrees\n",
    "\n",
    "# width of reach by stream order (order:width)\n",
    "river_widths = dict({1:10, 2:10, 3:20, 4:30, 5:30}) \n",
    "\n",
    "\n",
    "# Note that, by default, we tend to work in the DayMet CRS because this allows us to avoid\n",
    "# reprojecting meteorological forcing datasets.\n",
    "crs = watershed_workflow.crs.default_crs\n",
    "\n",
    "# start and stop time for simulation\n",
    "# note that this is the overlap of AORC and MODIS\n",
    "start = cftime.DatetimeGregorian(2007, 8, 1)\n",
    "end = cftime.DatetimeGregorian(2020, 7, 31)\n",
    "\n",
    "start_noleap = cftime.DatetimeNoLeap(2007, 8, 1)\n",
    "end_noleap = cftime.DatetimeNoLeap(2020, 7, 31)\n",
    "cyclic_nyears = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca08d34-72d2-4ecd-b940-30d9e3f43fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a dictionary of source objects\n",
    "#\n",
    "# Data sources, also called managers, deal with downloading and parsing data files from a variety of online APIs.\n",
    "sources = watershed_workflow.sources.getDefaultSources()\n",
    "\n",
    "# log the sources that will be used here\n",
    "watershed_workflow.sources.logSources(sources)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e3bfd1-3edf-48e6-b97d-3048c3b23734",
   "metadata": {},
   "source": [
    "## Reload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10313c38-fe29-45ad-808c-c51e67364be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fromOutput('02_watersheds.pickle'), 'rb') as fid:\n",
    "    watersheds = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee082ce6-6229-4392-90e6-437db52e8974",
   "metadata": {},
   "source": [
    "## Download AORC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67d7db1-39e3-4166-b415-94872199f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data, including:\n",
    "#  - lazy spatial subsetting to the watershed\n",
    "#  - chunked temporal_resampling to daily data\n",
    "#  - streamed directly to file\n",
    "met_data_request = sources['meteorology'].requestDataset(watersheds.exterior, crs, start, end, temporal_resampling='1D')\n",
    "\n",
    "time_chunk_size = 100\n",
    "met_data_chunked = sources['meteorology'].fetchRequest(met_data_request, chunk_time=time_chunk_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9133004-5678-470e-8bb2-f4e2b3b00d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aorc is a lat-lon product -- project it\n",
    "met_data_projected = watershed_workflow.warp.dataset(met_data_chunked, crs, 'bilinear', time_chunk_size, toOutput('warped meterology', 'warped_meteorology.nc'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcddb585-cb69-4ec5-b883-f2ec0cc4810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_data_projected['time']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927bb260-7b2b-429e-bba0-b0f27c8b4ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_data_transient = watershed_workflow.meteorology.convertAORCToATS(met_data_projected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b54aa-12d6-4f1c-b60b-1dfe2f640b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a few of the met data -- does it look reasonable?\n",
    "def plotMetData(met, x=5, y=5):\n",
    "    \"\"\"plot one pixel as a function of time\"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(221)\n",
    "    \n",
    "    met_data_single_pixel = met.isel({'time':slice(0,365*2),\n",
    "                                               'x' : x,\n",
    "                                               'y' : y})\n",
    "    \n",
    "    met_data_single_pixel['precipitation rain [m s^-1]'].plot(color='b', label='rain')\n",
    "    met_data_single_pixel['precipitation snow [m SWE s^-1]'].plot(color='c', label='snow')\n",
    "    ax.set_ylabel('precip [m s^-1]')\n",
    "    ax.set_title('')\n",
    "    ax.legend()\n",
    "    \n",
    "    ax = fig.add_subplot(222)\n",
    "    met_data_single_pixel['incoming shortwave radiation [W m^-2]'].plot(color='r', label='qSW_in')\n",
    "    ax.set_ylabel('incoming shortwave radiation [W m^-2]')\n",
    "    ax.set_title('')\n",
    "\n",
    "    ax = fig.add_subplot(223)\n",
    "    (met['precipitation rain [m s^-1]'][0:365].sum(axis=0)*86400*1000).plot.imshow()\n",
    "    ax.set_title('annual precip [mm]')\n",
    "\n",
    "    ax = fig.add_subplot(224)\n",
    "    met['incoming shortwave radiation [W m^-2]'][0].plot.imshow(cmap='hot')\n",
    "    ax.set_title('incoming radiation [W m^-2]')\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plotMetData(met_data_transient, 50,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8b7a01-e15e-4c57-b65e-5773e10b242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_data_transient['time'][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c19692-2f29-4abe-a4c2-1453d6fb00e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_data_transient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b447ee-dfe9-4a04-807c-6c7c0a5c0263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write transient data to disk\n",
    "filename = toOutput('meteorology_transient', f'{name}_aorc-{start.year}-{end.year}.h5')\n",
    "watershed_workflow.io.writeDatasetToHDF5(\n",
    "    filename,\n",
    "    met_data_transient\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17717fcf-9eb4-4708-9a16-7ff0a3c1ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the typical year\n",
    "met_data_typical = watershed_workflow.meteorology.computeTypicalYear(met_data_transient, cyclic_nyears)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc31024-6b57-4fb1-bc7f-3c7295a925ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMetData(met_data_typical, 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a51b23-5f9c-4148-a464-e38eeaf0e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write typical data to disk\n",
    "filename = toOutput('meteorology_typical', f'{name}_aorc_typical-{start.year-cyclic_nyears}-{start.year}.h5')\n",
    "watershed_workflow.io.writeDatasetToHDF5(\n",
    "    filename,\n",
    "    met_data_typical\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b472d-7ed4-4346-a47d-f239caef21fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also save an average P - ET = 0.6 * average P\n",
    "pavg = met_data_transient['precipitation rain [m s^-1]'].mean()\n",
    "\n",
    "with open(toOutput('total_avg_precip', 'total_avg_precip.pickle'), 'wb') as fid:\n",
    "    pickle.dump(float(pavg.values), fid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6495929c-7922-4670-8d50-8775c520f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lastly, reread, update, and output filenames\n",
    "with open(toOutput('05_output_filenames', '05_output_filenames.txt'), 'wb') as fid:\n",
    "    pickle.dump(output_filenames, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e375fb6c-d5b4-4d05-a2bd-a193134504cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ww-geopandas-20250725]",
   "language": "python",
   "name": "conda-env-ww-geopandas-20250725-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
